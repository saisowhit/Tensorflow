{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzicRVoOQ6aq",
        "outputId": "3cf66321-1850-42a8-f42f-afeecd4c8791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorflow\n",
        "!pip3 install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data=keras.datasets.fashion_mnist\n"
      ],
      "metadata": {
        "id": "5U7G441kRAcC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=data.load_data()"
      ],
      "metadata": {
        "id": "R2EHQqY8RDAA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_images=['T-shirt/top','Trouser','Dress','Coat','Sandal','shirt','Sneaker','Bag','Ankle boot']"
      ],
      "metadata": {
        "id": "SaDswzLyRJSL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0\n",
        "print(train_images[7])\n",
        "plt.imshow(train_images[7],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yzfk5BuJRH_r",
        "outputId": "fc3329c9-0032-45b3-846d-f475c7d605da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.00392157\n",
            "  0.00392157 0.         0.         0.         0.         0.24705882\n",
            "  0.10980392 0.         0.         0.         0.12941176 0.33333333\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.00784314\n",
            "  0.         0.         0.10980392 0.49411765 0.94509804 1.\n",
            "  1.         1.         1.         1.         1.         0.98823529\n",
            "  0.97254902 0.43529412 0.         0.         0.         0.00784314\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.00784314 0.\n",
            "  0.         0.80784314 0.95686275 0.98431373 0.94509804 0.90196078\n",
            "  0.93333333 0.86666667 0.80392157 0.90196078 0.94117647 0.90196078\n",
            "  0.9372549  0.98431373 0.91372549 0.64705882 0.         0.\n",
            "  0.00784314 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.00392157 0.         0.\n",
            "  0.78039216 0.98431373 0.89411765 0.91764706 0.91372549 0.9254902\n",
            "  0.92156863 0.96078431 0.96862745 0.92941176 0.91764706 0.9372549\n",
            "  0.90196078 0.90196078 0.92156863 1.         0.69019608 0.\n",
            "  0.         0.00392157 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.31764706\n",
            "  0.99607843 0.88627451 0.89411765 0.9372549  0.92941176 0.9254902\n",
            "  0.91764706 0.90980392 0.91372549 0.92156863 0.92156863 0.9254902\n",
            "  0.9372549  0.92941176 0.91372549 0.88235294 0.96470588 0.28627451\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.01176471 0.         0.         1.\n",
            "  0.92156863 0.9372549  0.8745098  0.91764706 0.93333333 0.9254902\n",
            "  0.92941176 0.9254902  0.92156863 0.92156863 0.92156863 0.92156863\n",
            "  0.9254902  0.92156863 0.91764706 0.90196078 0.90588235 1.\n",
            "  0.09411765 0.         0.01568627 0.        ]\n",
            " [0.         0.         0.         0.         0.69411765 0.9372549\n",
            "  0.8745098  0.99607843 0.8745098  0.90980392 0.91764706 0.91764706\n",
            "  0.9254902  0.9254902  0.92156863 0.92156863 0.92156863 0.92156863\n",
            "  0.92156863 0.91764706 0.90588235 0.91372549 0.87058824 0.96470588\n",
            "  0.34509804 0.         0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.91764706 0.9372549\n",
            "  0.89803922 1.         0.8627451  0.90980392 0.91372549 0.90980392\n",
            "  0.91764706 0.92156863 0.92156863 0.92156863 0.92156863 0.92156863\n",
            "  0.91764706 0.91372549 0.90980392 0.90196078 0.89411765 0.99607843\n",
            "  0.54901961 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.88235294 0.94117647\n",
            "  0.88627451 1.         0.86666667 0.89019608 0.90980392 0.89411765\n",
            "  0.90588235 0.90196078 0.89411765 0.89803922 0.90588235 0.90196078\n",
            "  0.89411765 0.89411765 0.90980392 0.8745098  0.89803922 0.95686275\n",
            "  0.90588235 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.18431373 0.96078431 0.90588235\n",
            "  0.91764706 0.97647059 0.89803922 0.86666667 0.89803922 0.88235294\n",
            "  0.89803922 0.89019608 0.88627451 0.89019608 0.89411765 0.89019608\n",
            "  0.89411765 0.89803922 0.89411765 0.87843137 0.96470588 0.94117647\n",
            "  0.89019608 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.2        0.97254902 0.90196078\n",
            "  0.96078431 0.96470588 0.90196078 0.88627451 0.90196078 0.89019608\n",
            "  0.90196078 0.89803922 0.89411765 0.89803922 0.90196078 0.89411765\n",
            "  0.89411765 0.90588235 0.88235294 0.89019608 0.94901961 0.92941176\n",
            "  1.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.39607843 0.99215686 0.89803922\n",
            "  0.96862745 0.94509804 0.86666667 0.91372549 0.89411765 0.89019608\n",
            "  0.89803922 0.89411765 0.89019608 0.89411765 0.90196078 0.89019608\n",
            "  0.90196078 0.91764706 0.88235294 0.89803922 0.98431373 0.89803922\n",
            "  0.95294118 0.21568627 0.         0.        ]\n",
            " [0.         0.         0.         0.4        1.         0.89019608\n",
            "  0.94901961 0.94509804 0.86666667 0.91764706 0.8745098  0.90196078\n",
            "  0.89411765 0.90588235 0.89803922 0.90588235 0.90588235 0.89019608\n",
            "  0.89803922 0.94509804 0.85882353 0.9254902  0.99607843 0.88235294\n",
            "  0.98039216 0.65490196 0.         0.        ]\n",
            " [0.         0.         0.         0.35294118 1.         0.89803922\n",
            "  0.9254902  0.90588235 0.87058824 0.9254902  0.8745098  0.90588235\n",
            "  0.89803922 0.90588235 0.89803922 0.90588235 0.90588235 0.89411765\n",
            "  0.87843137 0.96078431 0.85490196 0.95294118 0.9372549  0.89019608\n",
            "  0.95686275 0.68627451 0.         0.        ]\n",
            " [0.         0.         0.         0.83137255 0.98039216 0.88235294\n",
            "  0.9254902  0.97647059 0.89803922 0.92941176 0.8745098  0.90588235\n",
            "  0.89803922 0.90588235 0.89803922 0.90588235 0.90588235 0.90196078\n",
            "  0.86666667 0.95294118 0.88235294 0.97254902 0.90196078 0.9254902\n",
            "  0.91764706 1.         0.00392157 0.        ]\n",
            " [0.         0.         0.         0.96078431 0.95294118 0.90980392\n",
            "  0.95294118 0.85490196 0.89411765 0.93333333 0.87058824 0.90588235\n",
            "  0.89803922 0.90588235 0.89803922 0.90588235 0.90588235 0.90196078\n",
            "  0.87058824 0.92941176 0.92941176 0.98823529 0.89803922 0.9372549\n",
            "  0.94117647 0.8745098  0.         0.        ]\n",
            " [0.         0.         0.10588235 1.         0.92156863 0.94901961\n",
            "  0.92941176 0.84705882 0.90196078 0.9254902  0.87843137 0.89803922\n",
            "  0.89019608 0.91372549 0.91372549 0.91372549 0.90196078 0.89411765\n",
            "  0.87843137 0.90196078 0.96078431 0.96862745 0.86666667 0.95294118\n",
            "  0.9372549  0.98823529 0.         0.        ]\n",
            " [0.         0.         0.34509804 1.         0.90980392 0.97254902\n",
            "  0.9254902  0.81568627 0.91764706 0.90588235 0.8745098  0.89019608\n",
            "  0.88627451 0.91372549 0.90980392 0.90980392 0.90196078 0.89411765\n",
            "  0.87843137 0.87843137 0.92156863 0.91372549 0.91764706 0.96862745\n",
            "  0.92156863 1.         0.         0.        ]\n",
            " [0.         0.         0.3254902  1.         0.88235294 0.98039216\n",
            "  0.92941176 0.87843137 0.9254902  0.89803922 0.88235294 0.88235294\n",
            "  0.89019608 0.92156863 0.89803922 0.90588235 0.90196078 0.90196078\n",
            "  0.89019608 0.86666667 0.89019608 0.86666667 0.9372549  0.98039216\n",
            "  0.90588235 1.         0.         0.        ]\n",
            " [0.         0.         0.07843137 1.         0.87843137 0.97254902\n",
            "  0.91764706 0.88627451 0.90980392 0.87058824 0.88235294 0.87843137\n",
            "  0.90588235 0.93333333 0.88627451 0.90196078 0.89411765 0.90196078\n",
            "  0.90196078 0.86666667 0.89803922 0.88235294 0.95686275 0.96470588\n",
            "  0.90196078 1.         0.         0.        ]\n",
            " [0.         0.         0.37254902 1.         0.85490196 0.94901961\n",
            "  1.         0.90980392 0.88627451 0.87843137 0.89803922 0.89411765\n",
            "  0.89411765 0.90980392 0.89411765 0.89803922 0.90588235 0.91372549\n",
            "  0.90980392 0.88627451 0.86666667 0.87843137 0.96862745 0.95686275\n",
            "  0.89411765 1.         0.         0.        ]\n",
            " [0.         0.         0.65490196 1.         0.83529412 0.92156863\n",
            "  1.         0.31764706 0.96078431 0.98431373 0.93333333 0.9254902\n",
            "  0.90196078 0.89803922 0.90196078 0.89803922 0.90196078 0.90588235\n",
            "  0.93333333 0.94117647 1.         0.75294118 1.         0.9372549\n",
            "  0.89411765 1.         0.09019608 0.        ]\n",
            " [0.         0.         0.67843137 0.94901961 0.87843137 0.91372549\n",
            "  1.         0.         0.53333333 0.88627451 0.9372549  1.\n",
            "  0.89803922 0.9254902  0.9254902  0.91764706 0.91372549 0.89411765\n",
            "  0.98431373 0.97254902 0.78431373 0.31764706 1.         0.92941176\n",
            "  0.88235294 1.         0.39607843 0.        ]\n",
            " [0.         0.         0.6745098  1.         0.88627451 0.91372549\n",
            "  1.         0.         0.         0.         0.         0.\n",
            "  0.03137255 0.08235294 0.08627451 0.08235294 0.07843137 0.05490196\n",
            "  0.         0.         0.         0.         1.         0.93333333\n",
            "  0.89803922 0.96470588 0.69803922 0.        ]\n",
            " [0.         0.         0.0627451  1.         0.9254902  0.93333333\n",
            "  0.98823529 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.87058824 0.95686275\n",
            "  0.87058824 0.99607843 0.46666667 0.        ]\n",
            " [0.         0.         0.         0.11764706 0.89411765 0.94901961\n",
            "  0.63921569 0.         0.         0.         0.         0.00784314\n",
            "  0.01568627 0.02352941 0.01960784 0.01960784 0.01568627 0.01568627\n",
            "  0.00784314 0.         0.00392157 0.         0.59215686 0.98431373\n",
            "  0.92156863 0.70588235 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.91764706 1.\n",
            "  0.74901961 0.         0.04313725 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01568627 0.         0.40392157 0.96470588\n",
            "  0.96862745 0.28235294 0.         0.        ]\n",
            " [0.         0.         0.         0.00392157 0.37254902 0.30196078\n",
            "  0.20392157 0.         0.01568627 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01176471 0.         0.32156863 0.92941176\n",
            "  0.90588235 0.2745098  0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a model"
      ],
      "metadata": {
        "id": "lbt4IhcaRNP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential([keras.layers.Flatten(input_shape=(28,28)),keras.layers.Dense(128,activation=\"relu\"),keras.layers.Dense(10,activation=\"softmax\")])\n",
        "model.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10)\n",
        "# test_loss,test_acc=model.evaluate(test_images,test_labels)\n",
        "# print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1-e4JZbRO8A",
        "outputId": "8c8abc03-1c46-4653-f1d7-2e6880f3a9b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.6339\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3816\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.3383\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8861 - loss: 0.3084\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.2963\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.2776\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9012 - loss: 0.2674\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9046 - loss: 0.2583\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.2435\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9122 - loss: 0.2385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b50b2466f60>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction=model.predict(test_images[7])\n",
        "# for i in range(5):\n",
        "#     plt.imshow(test_images[i],cmap=plt.cmap.binary)\n",
        "#     plt.xlabel(\"Actual:\"+class_images[test_labels[i]])\n",
        "#     plt.title(\"Prediction:\"+class_images[np.argmax(prediction[i])])\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "aoNtDnchZ7Vk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## text classification with movie review"
      ],
      "metadata": {
        "id": "KL-tsMzcb2bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=keras.datasets.imdb"
      ],
      "metadata": {
        "id": "pfZyuYvTb5JF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data,train_labesl),(test_data,test_labels)=data.load_data(num_words=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPyrMx_ocCeV",
        "outputId": "d084ea3f-c590-436a-f48b-5a49b1f2d475"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0zIfqgkcKzj",
        "outputId": "9a1a4984-4f19-4a7c-c52b-206ddd2d6792"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index=data.get_word_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMMxc6EvcNbz",
        "outputId": "99c2806a-110f-4a00-d6db-a592aba98712"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index={k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"]=0\n",
        "word_index[\"<START>\"]=1\n",
        "word_index[\"<UNK>\"]=2\n",
        "revese_word_index=dict([(value,key) for (key,value) in word_index.items()])\n",
        "train_data=keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
        "test_data=keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
        "def decode_review(text):\n",
        "  return \"\".join([revese_word_index.get(i,\"?\") for i in text])"
      ],
      "metadata": {
        "id": "tFo2u95xcR5W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0],len(test_data[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWuf2wencq3K",
        "outputId": "c3458511-2751-489b-d94b-c1f407c0e297"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1 591 202  14  31   6 717  10  10   2   2   5   4 360   7   4 177   2\n",
            " 394 354   4 123   9   2   2   2  10  10  13  92 124  89 488   2 100  28\n",
            "   2  14  31  23  27   2  29 220 468   8 124  14 286 170   8 157  46   5\n",
            "  27 239  16 179   2  38  32  25   2 451 202  14   6 717   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential()\n",
        "model.add(keras.layers.Embedding(88000,16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16,activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "MMZboITdcyGT",
        "outputId": "4551188d-c8ea-43eb-e18d-30bae0bc2029"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding layer Text classification"
      ],
      "metadata": {
        "id": "1oYOtep-d0pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "x_val=train_data[:10000]"
      ],
      "metadata": {
        "id": "cQTbi1r_ik4V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data,train_labesl,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Umr2PBi1uu",
        "outputId": "5fd4b61a-0851-4a1c-b66c-56ed703c9838"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8649 - loss: 0.3178\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8681 - loss: 0.3137\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8684 - loss: 0.3126\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.8701 - loss: 0.3069\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8654 - loss: 0.3144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5067383c80>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.evaluate(test_data,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZRiYs-RifBn",
        "outputId": "d83d2bf9-fabc-45e1-b1bf-34ed9f773f7c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.3339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOux3Q35ioMo",
        "outputId": "8440ae88-4897-44f8-f6b9-68fbb9471efa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3329494595527649, 0.85316002368927]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 250\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "test_review_padded = pad_sequences([test_review], maxlen=maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "KZyaiIIqtqiR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(test_review_padded)\n",
        "predicted_class = predict.argmax(axis=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FPiildctnYZ",
        "outputId": "a54610f6-2ffa-46af-8d92-5aee33384a4d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Review:\", decode_review(test_review))\n",
        "print(\"Prediction:\", predicted_class)\n",
        "print(\"Actual:\", test_labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYC0rXnHtxiU",
        "outputId": "8be1d279-7323-402c-f08e-7fe04505bdb6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: <START>toldhowever?with?future??<UNK><UNK>??given??actually<UNK>perhaps3?many?<UNK><UNK><UNK>???willbeingbeenchildren<UNK>becausewas<UNK>?withinthat<UNK>asrightlives?being?book10?backby?thatbitthedirector<UNK>aremoviei<UNK>problemhowever??future<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "Prediction: 0\n",
            "Actual: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## saving the model"
      ],
      "metadata": {
        "id": "HQoJ8BCukLqf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]        # will have 40000 samples\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]"
      ],
      "metadata": {
        "id": "aF-HN451unr-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elKTfJw8uxTS",
        "outputId": "818bae07-21e3-4320-aa5d-5d6e2aac3ee2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15000, 250) (50000,)\n",
            "(10000, 250) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # fit_model = model.fit(\n",
        "# #     x_train, y_train,\n",
        "# #     validation_data=(x_val, y_val),\n",
        "# #     epochs=40,\n",
        "# #     batch_size=512\n",
        "# )"
      ],
      "metadata": {
        "id": "Ff0fiZXXu1C4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "min_len = min(len(train_data), len(train_labels))\n",
        "train_data = train_data[:min_len]\n",
        "train_labels = train_labels[:min_len]\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    train_data, train_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, batch_size=512)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw2cK3vBuIVt",
        "outputId": "a4c41704-54c2-49cf-c7c8-fae7890d814e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1036 - loss: -164500.9688 - val_accuracy: 0.0994 - val_loss: -190258.9062\n",
            "Epoch 2/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1005 - loss: -194532.5000 - val_accuracy: 0.0994 - val_loss: -220702.0312\n",
            "Epoch 3/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1014 - loss: -224203.3594 - val_accuracy: 0.0994 - val_loss: -252772.9844\n",
            "Epoch 4/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1032 - loss: -254127.1094 - val_accuracy: 0.0994 - val_loss: -286352.4375\n",
            "Epoch 5/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.1002 - loss: -290979.4375 - val_accuracy: 0.0994 - val_loss: -322031.4375\n",
            "Epoch 6/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1054 - loss: -325498.7812 - val_accuracy: 0.0994 - val_loss: -359147.4062\n",
            "Epoch 7/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1002 - loss: -364522.7188 - val_accuracy: 0.0994 - val_loss: -397802.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.0984 - loss: -401274.8125 - val_accuracy: 0.0994 - val_loss: -438152.2500\n",
            "Epoch 9/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.1026 - loss: -440997.8125 - val_accuracy: 0.0994 - val_loss: -479997.6875\n",
            "Epoch 10/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.1013 - loss: -485666.0625 - val_accuracy: 0.0994 - val_loss: -523434.9062\n",
            "Epoch 11/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0980 - loss: -526741.6250 - val_accuracy: 0.0994 - val_loss: -568493.6250\n",
            "Epoch 12/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.0996 - loss: -571186.0000 - val_accuracy: 0.0994 - val_loss: -615416.1875\n",
            "Epoch 13/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.1002 - loss: -615657.0000 - val_accuracy: 0.0994 - val_loss: -663841.4375\n",
            "Epoch 14/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1014 - loss: -664033.5625 - val_accuracy: 0.0994 - val_loss: -713698.7500\n",
            "Epoch 15/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1001 - loss: -716699.6250 - val_accuracy: 0.0994 - val_loss: -765440.3125\n",
            "Epoch 16/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0992 - loss: -760357.6250 - val_accuracy: 0.0994 - val_loss: -818318.4375\n",
            "Epoch 17/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.1054 - loss: -815291.2500 - val_accuracy: 0.0994 - val_loss: -873090.4375\n",
            "Epoch 18/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.1044 - loss: -866249.3125 - val_accuracy: 0.0994 - val_loss: -929276.7500\n",
            "Epoch 19/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1030 - loss: -923952.8125 - val_accuracy: 0.0994 - val_loss: -987361.0000\n",
            "Epoch 20/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1015 - loss: -985845.8750 - val_accuracy: 0.0994 - val_loss: -1047027.6875\n",
            "Epoch 21/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1015 - loss: -1048975.7500 - val_accuracy: 0.0994 - val_loss: -1107910.1250\n",
            "Epoch 22/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1014 - loss: -1101859.3750 - val_accuracy: 0.0994 - val_loss: -1170475.0000\n",
            "Epoch 23/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1003 - loss: -1169537.8750 - val_accuracy: 0.0994 - val_loss: -1234800.3750\n",
            "Epoch 24/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1025 - loss: -1226633.1250 - val_accuracy: 0.0994 - val_loss: -1300571.1250\n",
            "Epoch 25/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1017 - loss: -1300310.2500 - val_accuracy: 0.0994 - val_loss: -1367865.8750\n",
            "Epoch 26/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0979 - loss: -1361790.2500 - val_accuracy: 0.0994 - val_loss: -1436705.3750\n",
            "Epoch 27/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1046 - loss: -1425695.2500 - val_accuracy: 0.0994 - val_loss: -1507397.6250\n",
            "Epoch 28/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0999 - loss: -1511202.3750 - val_accuracy: 0.0994 - val_loss: -1579638.6250\n",
            "Epoch 29/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1022 - loss: -1563174.7500 - val_accuracy: 0.0994 - val_loss: -1652910.5000\n",
            "Epoch 30/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1028 - loss: -1645712.7500 - val_accuracy: 0.0994 - val_loss: -1728121.6250\n",
            "Epoch 31/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1022 - loss: -1709856.7500 - val_accuracy: 0.0994 - val_loss: -1804492.1250\n",
            "Epoch 32/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1019 - loss: -1793909.7500 - val_accuracy: 0.0994 - val_loss: -1882671.7500\n",
            "Epoch 33/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.1027 - loss: -1852229.2500 - val_accuracy: 0.0994 - val_loss: -1962052.8750\n",
            "Epoch 34/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1042 - loss: -1937578.1250 - val_accuracy: 0.0994 - val_loss: -2043682.8750\n",
            "Epoch 35/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1003 - loss: -2018683.3750 - val_accuracy: 0.0994 - val_loss: -2126888.2500\n",
            "Epoch 36/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0972 - loss: -2115645.2500 - val_accuracy: 0.0994 - val_loss: -2211411.2500\n",
            "Epoch 37/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1019 - loss: -2201626.2500 - val_accuracy: 0.0994 - val_loss: -2297571.0000\n",
            "Epoch 38/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1001 - loss: -2279719.5000 - val_accuracy: 0.0994 - val_loss: -2385028.7500\n",
            "Epoch 39/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1035 - loss: -2363666.7500 - val_accuracy: 0.0994 - val_loss: -2473983.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1028 - loss: -2441326.7500 - val_accuracy: 0.0994 - val_loss: -2564499.0000\n",
            "Epoch 41/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1014 - loss: -2546610.5000 - val_accuracy: 0.0994 - val_loss: -2657094.2500\n",
            "Epoch 42/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1008 - loss: -2625848.7500 - val_accuracy: 0.0994 - val_loss: -2750732.5000\n",
            "Epoch 43/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.1024 - loss: -2757096.7500 - val_accuracy: 0.0994 - val_loss: -2846602.7500\n",
            "Epoch 44/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.0998 - loss: -2823187.2500 - val_accuracy: 0.0994 - val_loss: -2944035.7500\n",
            "Epoch 45/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1018 - loss: -2953985.2500 - val_accuracy: 0.0994 - val_loss: -3043293.5000\n",
            "Epoch 46/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0990 - loss: -3008108.7500 - val_accuracy: 0.0994 - val_loss: -3143305.7500\n",
            "Epoch 47/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1027 - loss: -3090808.5000 - val_accuracy: 0.0994 - val_loss: -3244929.0000\n",
            "Epoch 48/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.0991 - loss: -3209761.5000 - val_accuracy: 0.0994 - val_loss: -3349141.2500\n",
            "Epoch 49/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.1060 - loss: -3291608.0000 - val_accuracy: 0.0994 - val_loss: -3454629.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1011 - loss: -3401899.5000 - val_accuracy: 0.0994 - val_loss: -3561438.5000\n",
            "Epoch 51/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.1033 - loss: -3543858.5000 - val_accuracy: 0.0994 - val_loss: -3670082.2500\n",
            "Epoch 52/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.1050 - loss: -3616613.5000 - val_accuracy: 0.0994 - val_loss: -3780361.5000\n",
            "Epoch 53/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1015 - loss: -3714794.7500 - val_accuracy: 0.0994 - val_loss: -3892512.2500\n",
            "Epoch 54/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0978 - loss: -3880030.2500 - val_accuracy: 0.0994 - val_loss: -4006171.5000\n",
            "Epoch 55/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1014 - loss: -3946489.5000 - val_accuracy: 0.0994 - val_loss: -4121267.5000\n",
            "Epoch 56/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1011 - loss: -4091250.7500 - val_accuracy: 0.0994 - val_loss: -4237927.5000\n",
            "Epoch 57/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.1004 - loss: -4238751.5000 - val_accuracy: 0.0994 - val_loss: -4356702.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0974 - loss: -4311365.5000 - val_accuracy: 0.0994 - val_loss: -4477079.5000\n",
            "Epoch 59/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1013 - loss: -4398259.0000 - val_accuracy: 0.0994 - val_loss: -4599319.5000\n",
            "Epoch 60/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1007 - loss: -4551614.5000 - val_accuracy: 0.0994 - val_loss: -4723453.0000\n",
            "Epoch 61/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.1025 - loss: -4708117.5000 - val_accuracy: 0.0994 - val_loss: -4850024.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1016 - loss: -4790517.0000 - val_accuracy: 0.0994 - val_loss: -4977637.5000\n",
            "Epoch 63/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1037 - loss: -4886639.0000 - val_accuracy: 0.0994 - val_loss: -5106478.5000\n",
            "Epoch 64/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1033 - loss: -5056242.5000 - val_accuracy: 0.0994 - val_loss: -5238101.0000\n",
            "Epoch 65/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1006 - loss: -5206060.5000 - val_accuracy: 0.0994 - val_loss: -5371539.5000\n",
            "Epoch 66/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1006 - loss: -5320267.5000 - val_accuracy: 0.0994 - val_loss: -5506524.0000\n",
            "Epoch 67/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1019 - loss: -5384640.5000 - val_accuracy: 0.0994 - val_loss: -5641394.0000\n",
            "Epoch 68/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1009 - loss: -5588503.0000 - val_accuracy: 0.0994 - val_loss: -5779445.0000\n",
            "Epoch 69/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1028 - loss: -5733704.5000 - val_accuracy: 0.0994 - val_loss: -5919705.0000\n",
            "Epoch 70/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.1029 - loss: -5750781.0000 - val_accuracy: 0.0994 - val_loss: -6060759.5000\n",
            "Epoch 71/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.1025 - loss: -6033810.0000 - val_accuracy: 0.0994 - val_loss: -6204585.5000\n",
            "Epoch 72/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1024 - loss: -6168718.0000 - val_accuracy: 0.0994 - val_loss: -6349495.5000\n",
            "Epoch 73/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1037 - loss: -6261542.5000 - val_accuracy: 0.0994 - val_loss: -6496580.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1018 - loss: -6402979.0000 - val_accuracy: 0.0994 - val_loss: -6646114.0000\n",
            "Epoch 75/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1025 - loss: -6550583.5000 - val_accuracy: 0.0994 - val_loss: -6796596.5000\n",
            "Epoch 76/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1017 - loss: -6711648.0000 - val_accuracy: 0.0994 - val_loss: -6949657.0000\n",
            "Epoch 77/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1028 - loss: -6867089.5000 - val_accuracy: 0.0994 - val_loss: -7104079.5000\n",
            "Epoch 78/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0982 - loss: -7072523.0000 - val_accuracy: 0.0994 - val_loss: -7260315.5000\n",
            "Epoch 79/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1025 - loss: -7149755.5000 - val_accuracy: 0.0994 - val_loss: -7419635.5000\n",
            "Epoch 80/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.0990 - loss: -7385121.0000 - val_accuracy: 0.0994 - val_loss: -7579557.0000\n",
            "Epoch 81/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.1018 - loss: -7429253.0000 - val_accuracy: 0.0994 - val_loss: -7741473.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1039 - loss: -7619345.5000 - val_accuracy: 0.0994 - val_loss: -7904695.0000\n",
            "Epoch 83/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1037 - loss: -7841865.5000 - val_accuracy: 0.0994 - val_loss: -8070775.0000\n",
            "Epoch 84/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1011 - loss: -7940966.0000 - val_accuracy: 0.0994 - val_loss: -8237918.0000\n",
            "Epoch 85/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1036 - loss: -8130560.5000 - val_accuracy: 0.0994 - val_loss: -8408400.0000\n",
            "Epoch 86/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0993 - loss: -8391215.0000 - val_accuracy: 0.0994 - val_loss: -8579741.0000\n",
            "Epoch 87/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1036 - loss: -8475140.0000 - val_accuracy: 0.0994 - val_loss: -8753058.0000\n",
            "Epoch 88/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.1020 - loss: -8739715.0000 - val_accuracy: 0.0994 - val_loss: -8928163.0000\n",
            "Epoch 89/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.1038 - loss: -8852428.0000 - val_accuracy: 0.0994 - val_loss: -9105405.0000\n",
            "Epoch 90/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.0980 - loss: -9080269.0000 - val_accuracy: 0.0994 - val_loss: -9284421.0000\n",
            "Epoch 91/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0971 - loss: -9198741.0000 - val_accuracy: 0.0994 - val_loss: -9466401.0000\n",
            "Epoch 92/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1050 - loss: -9339943.0000 - val_accuracy: 0.0994 - val_loss: -9648149.0000\n",
            "Epoch 93/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1028 - loss: -9461345.0000 - val_accuracy: 0.0994 - val_loss: -9832283.0000\n",
            "Epoch 94/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1045 - loss: -9662500.0000 - val_accuracy: 0.0994 - val_loss: -10018932.0000\n",
            "Epoch 95/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0995 - loss: -9899030.0000 - val_accuracy: 0.0994 - val_loss: -10207919.0000\n",
            "Epoch 96/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1022 - loss: -10080510.0000 - val_accuracy: 0.0994 - val_loss: -10400383.0000\n",
            "Epoch 97/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.1014 - loss: -10247463.0000 - val_accuracy: 0.0994 - val_loss: -10593050.0000\n",
            "Epoch 98/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0997 - loss: -10470762.0000 - val_accuracy: 0.0994 - val_loss: -10788272.0000\n",
            "Epoch 99/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.1025 - loss: -10623199.0000 - val_accuracy: 0.0994 - val_loss: -10984446.0000\n",
            "Epoch 100/100\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0997 - loss: -10784833.0000 - val_accuracy: 0.0994 - val_loss: -11183748.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b506a1cad20>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.evaluate(test_data,test_labels)\n",
        "print(results)\n",
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsZXTFbFvmRq",
        "outputId": "01fe0ca1-528d-4b96-f2a4-dafd2db98852"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4927 - loss: 1583127.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1559490.125, 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.load_model(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5xqBaAv0t3",
        "outputId": "7d2f54ad-bf5d-46b5-c180-63c9fe4834f6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def review_encode(s):\n",
        "    encoded = [1]\n",
        "    for word in s:\n",
        "        if word.lower() in word_index:\n",
        "            encoded.append(word_index[word.lower()])\n",
        "        else:\n",
        "            encoded.append(2)\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "JInOXG9EzlVe"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test.txt\", encoding=\"utf-8\") as f:\n",
        "    for line in f.readlines():\n",
        "        nline = line.replace(\",\", \"\").replace(\".\", \"\").lower().split()  # tokenize words\n",
        "        # Convert words to integers using word_index\n",
        "        encode =review_encode(nline)\n",
        "        encode = pad_sequences([encode], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "        # Predict\n",
        "        predict = model.predict(encode)\n",
        "        print(line)\n",
        "        print(encode)\n",
        "        print(predict[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZq5XYQCx7T8",
        "outputId": "4e6ea72c-b842-4255-fa56-d02112545eb8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "The Walt Disney Company, commonly referred to as simply Disney, is an American multinational mass media and entertainment conglomerate headquartered at the Walt Disney Studios complex in Burbank, California. Disney was founded on October 16, 1923, as an animation studio by brothers Walt Disney and Roy Oliver Disney as Disney Brothers Cartoon Studio; it later operated under the names Walt Disney Studio and Walt Disney Productions before adopting its current name in 1986. In 1928, Disney established itself as a leader in the animation industry with the short film Steamboat Willie. The film used synchronized sound to become the first post-produced sound cartoon, and popularized Mickey Mouse,[4] who became Disney's mascot and corporate icon.[5]\n",
            "\n",
            "[[    1    16  6311   922  1181 12309  5426    20    29   343   922    21\n",
            "     47   310 25644  2981  1788    17   734 25926 85588    45    16  6311\n",
            "    922  2842  1327    23 27574  2654   922    28 13214    35  7461  3260\n",
            "  75082    29    47   760  1194    46  1106  6311   922    17  2368  2414\n",
            "    922    29   922  1106  1084     2    24   315 20131   479    16  1445\n",
            "   6311   922  1194    17  6311   922  2675   171 21654   106  2040   415\n",
            "     23  5486    23 11355   922  2933   422    29    18  2133    23    16\n",
            "    760  1612    31    16   358    34 31947  5110    16    34   355 11973\n",
            "    493    20   425    16    98     2   493  1084    17 32239  4123     2\n",
            "     49   889  4683 39350    17  4464     2     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "\n",
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "After becoming a success by the early 1940s,[6][7][8] Disney diversified into live-action films, television, and theme parks in the 1950s. However, following Walt Disney's death in 1966, the company's profits, especially in the animation sector, began to decline. In 1984, Disney's shareholders voted Michael Eisner as CEO, who led a reversal of the company's decline through a combination of international theme park expansion and the highly successful Disney Renaissance period of animation from 1989 to 1999. In 2005, under the new CEO Bob Iger, the company continued to expand into a major entertainment conglomerate with the acquisitions of Pixar in 2006, Marvel Entertainment in 2009, Lucasfilm in 2012, and 21st Century Fox in 2019. In 2020, Bob Chapek became the head of Disney after Iger's retirement. However, Chapek was ousted in 2022 and Iger was reinstated as CEO.[9]\n",
            "\n",
            "[[    1   115  1587    18  1035    46    16   414     2   922 33804    95\n",
            "      2   120   711    17   768  8676    23    16  3077   202  1057  6311\n",
            "   4683   353    23  8148    16 13685 10468   274    23    16   760 22407\n",
            "   1707    20  6267    23  4919  4683 73087  5893   500 22563    29 15247\n",
            "     49  1650    18 12198    19    16 13685  6267   155    18  2233    19\n",
            "   1978   768  1559 17797    17    16   557  1124   922  5832   822    19\n",
            "    760    51  5539    20  4218    23  3361   479    16   174 15247  2058\n",
            "      2    16  1181  3513    20  9262    95    18   690   734 25926    31\n",
            "     16     2    19  6580    23  2957  5659   734    23  7869     2    23\n",
            "  36381    17  6173  1129  1687    23 43852    23 50038  2058     2   889\n",
            "     16   431    19   922   115     2  8410   202     2    28 36531    23\n",
            "  17637    17     2    28 75575    29     2     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\n",
            "\n",
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Disney operates the largest television and film studio in Hollywood.[10] Walt Disney Studios includes Walt Disney Pictures, Walt Disney Animation Studios, Pixar, Marvel Studios, Lucasfilm, 20th Century Studios, 20th Century Animation, and Searchlight Pictures. Disney's other main business units include divisions operating the ABC television network; cable television networks such as Disney Channel, ESPN, Freeform, FX, and National Geographic; publishing, merchandising, music, and theater divisions; direct-to-consumer streaming services such as Disney+, ESPN+, Hulu, and Hotstar; and Disney Experiences, which includes several theme parks, resort hotels, and cruise lines around the world.\n",
            "\n",
            "[[    1   922 11708    16  9224   711    17    34  1194    23     2  6311\n",
            "    922  2842  1699  6311   922  1280  6311   922   760  2842  6580  5659\n",
            "   2842     2  3658  1129  2842  3658  1129   760    17 55836  1280  4683\n",
            "     97   305   982 16733  1482 28654  8896    16  3912   711     2  1889\n",
            "    711  8072   153    29   922  1320 35569 85103  3721    17  2094     2\n",
            "  21113 21548   240    17   762     2     2 19776  7284   153    29     2\n",
            "      2 27587    17     2    17   922  2502    75  1699   462   768  8676\n",
            "   4725 15713    17  3802   423   199    16   194     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "\n",
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[1.]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Disney is one of the biggest and best-known companies in the world.[11] In 2023, it was ranked 87th on the 2023 Forbes Global 2000,[12] and 48th on the Fortune 500 list of biggest companies in the United States by revenue.[13] Since its founding, the company has won 135 Academy Awards, 26 of which were awarded to Walt. The company has produced films which have been featured on many lists of the greatest films of all time and is one of the key players on the development of the theme park industry. The company has been public since 1940 and trades on the New York Stock Exchange (NYSE) and has been a component of the Dow Jones Industrial Average since 1991. In August 2020, about two-thirds of the stock was owned by large financial institutions. The company celebrated its 100th anniversary on October 16, 2023.\n",
            "[[    1   922    21    43    19    16  1138    17     2  5169    23    16\n",
            "      2    23 82073    24    28 10699     2    35    16 82073  8743  4576\n",
            "      2    17     2    35    16  3212  8355  1041    19  1138  5169    23\n",
            "     16  2363  1642    46     2   249   106 18215    16  1181    59  1211\n",
            "  25753  1821  2140  7625    19    75    83  8181    20  6311    16  1181\n",
            "     59  1067   120    75    40    89  2573    35   123  8710    19    16\n",
            "    845   120    19    44    70    17    21    43    19    16  1329  1862\n",
            "     35    16   955    19    16   768  1559  1612    16  1181    59    89\n",
            "   1083   249  5896    17 15487    35    16   174   794  2065  5128     2\n",
            "     17    59    89    18 10892    19    16     2  1544  5406   868   249\n",
            "   6059    23  7008 50038    56     2    19    16  2065    28  6442    46\n",
            "   1070  4130 20337    16  1181  6553   106 26254 10197    35  7461  3260\n",
            "  82073     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "[1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4NUasNlv4QA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}